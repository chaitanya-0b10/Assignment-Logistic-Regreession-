{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b85210d9-d72e-48c9-bda2-39cef6a4b48d",
   "metadata": {},
   "source": [
    "# Assignment : Logistic Regreession "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf986260-f8ca-4a01-9ded-7fe229bdf64c",
   "metadata": {},
   "source": [
    "## Theory Question "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb67c1bb-cb47-41c9-8747-9967329e8321",
   "metadata": {},
   "source": [
    " Q1. What is Logistic Regression, and how does it differ from Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ba5452c2-305b-4039-8d7a-d170b1d95059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\nLogistic Regression is a statistical method for predicting binary outcomes. \\nIt's used when the dependent variable is categorical, meaning it has two possible outcomes (0/1, True/False, Yes/No).\\nInstead of predicting the exact value, Logistic Regression estimates the probability that a given input point belongs to \\na particular category.\\n\\nDifferences:-\\nOutcome Type: Logistic Regression predicts probabilities and is used for classification tasks, \\nwhereas Linear Regression predicts a continuous value.\\n\\nModel Output: Logistic Regression outputs probabilities that are mapped to classes (0 or 1), \\nwhile Linear Regression outputs a numerical value directly.\\n\\nFunction: Logistic Regression uses the logistic function (sigmoid),\\nwhereas Linear Regression uses a linear function.\\n\""
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "Logistic Regression is a statistical method for predicting binary outcomes. \n",
    "It's used when the dependent variable is categorical, meaning it has two possible outcomes (0/1, True/False, Yes/No).\n",
    "Instead of predicting the exact value, Logistic Regression estimates the probability that a given input point belongs to \n",
    "a particular category.\n",
    "\n",
    "Differences:-\n",
    "Outcome Type: Logistic Regression predicts probabilities and is used for classification tasks, \n",
    "whereas Linear Regression predicts a continuous value.\n",
    "\n",
    "Model Output: Logistic Regression outputs probabilities that are mapped to classes (0 or 1), \n",
    "while Linear Regression outputs a numerical value directly.\n",
    "\n",
    "Function: Logistic Regression uses the logistic function (sigmoid),\n",
    "whereas Linear Regression uses a linear function.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106fea94-acc1-4442-a8f1-1717c0696b52",
   "metadata": {},
   "source": [
    " Q2. What is the mathematical equation of Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "864ee861-0435-4589-92c7-2fe94ac15a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Logistic Regression Equation\\n\\nThis equation uses the logistic (sigmoid) function to predict the probability of the binary outcome.\\n \\nP(y = 1|x) = 1/1+e^-(B0+B1x1+B2x2+.....+Bnxn)\\n\\n-> P(y = 1|x) is the probability of the outcome being 1\\n-> B0, B1,....., Bn are the coefficients (parameters) to be learned from the data\\n-> x1, x2,...., xn are the independent variables(features)\\n\\n'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Logistic Regression Equation\n",
    "\n",
    "This equation uses the logistic (sigmoid) function to predict the probability of the binary outcome.\n",
    " \n",
    "P(y = 1|x) = 1/1+e^-(B0+B1x1+B2x2+.....+Bnxn)\n",
    "\n",
    "-> P(y = 1|x) is the probability of the outcome being 1\n",
    "-> B0, B1,....., Bn are the coefficients (parameters) to be learned from the data\n",
    "-> x1, x2,...., xn are the independent variables(features)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b3b9dd-58b9-4ecb-a503-cf1f9bdc2593",
   "metadata": {},
   "source": [
    "Q3. Why do we use the Sigmoid function in Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e4a0f35a-17b9-4e1a-99b5-ded16f06d99c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We use the sigmoid function in Logistic Regression because it maps any real-valued number into \\na value between 0 and 1. This is crucial for predicting probabilities, which must fall within this range. \\nThe sigmoid function, ensures the output is interpretable as a probability, making it perfect for classification \\ntasks where we need to distinguish between two classes (e.g., spam/not spam).\\n\\nIn short, the sigmoid function helps transform the linear combination of inputs into a probability \\nthat can be used for binary classification.'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"We use the sigmoid function in Logistic Regression because it maps any real-valued number into \n",
    "a value between 0 and 1. This is crucial for predicting probabilities, which must fall within this range. \n",
    "The sigmoid function, ensures the output is interpretable as a probability, making it perfect for classification \n",
    "tasks where we need to distinguish between two classes (e.g., spam/not spam).\n",
    "\n",
    "In short, the sigmoid function helps transform the linear combination of inputs into a probability \n",
    "that can be used for binary classification.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf314f49-7c5c-4f79-92b1-9cccc3ecf635",
   "metadata": {},
   "source": [
    "Q4.  What is the cost function of Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d302cc5e-cb29-46f2-883a-481ffd0ed035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The cost function in Logistic Regression is used to measure how well the model's predictions match the actual data.\\nIt's called the Log-Loss or Cross-Entropy Loss function. The cost function aims to minimize the difference between the \\npredicted probabilities and the actual class labels.\""
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"The cost function in Logistic Regression is used to measure how well the model's predictions match the actual data.\n",
    "It's called the Log-Loss or Cross-Entropy Loss function. The cost function aims to minimize the difference between the \n",
    "predicted probabilities and the actual class labels.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58be3b28-279d-4492-a915-3aad51e5645a",
   "metadata": {},
   "source": [
    "Q5. What is Regularization in Logistic Regression? Why is it needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d5fe0341-96d6-438a-a7d6-7924c82541a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Regularization is a technique used in Logistic Regression to prevent overfitting by adding \\na penalty to the cost function.\\n\\nWhy is Regularization Needed?\\nPrevent Overfitting: It helps the model generalize better to unseen data by discouraging overly complex models.\\n\\nSimplify the Model: Encourages smaller coefficients, leading to simpler models that are easier to interpret.\\n\\nFeature Selection: L1 regularization can lead to sparse models by driving some coefficients to zero, \\neffectively selecting relevant features.\\n\\n'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Regularization is a technique used in Logistic Regression to prevent overfitting by adding \n",
    "a penalty to the cost function.\n",
    "\n",
    "Why is Regularization Needed?\n",
    "Prevent Overfitting: It helps the model generalize better to unseen data by discouraging overly complex models.\n",
    "\n",
    "Simplify the Model: Encourages smaller coefficients, leading to simpler models that are easier to interpret.\n",
    "\n",
    "Feature Selection: L1 regularization can lead to sparse models by driving some coefficients to zero, \n",
    "effectively selecting relevant features.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797a8880-e9d5-4925-97c6-b48920362f5e",
   "metadata": {},
   "source": [
    "Q6. Explain the difference between Lasso, Ridge, and Elastic Net regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "fc538ef5-d2d8-429d-9d4f-748d10130fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nLasso Regression (L1 Regularization):\\nPenalty: Adds the absolute values of the coefficients.\\nEffect: Can shrink some coefficients to zero, effectively performing feature selection.\\nUse Case: When you want to identify the most important features.\\n\\nRidge Regression (L2 Regularization):\\nPenalty: Adds the squared values of the coefficients.\\nEffect: Shrinks coefficients but does not set them to zero. All features are kept in the model.\\nUse Case: When you want to prevent overfitting while keeping all features.\\n\\nElastic Net Regression:\\nPenalty: Combines L1 and L2 regularization.\\nEffect: Balances the benefits of both Lasso and Ridge. It can select important features (like Lasso) while also handling multicollinearity (like Ridge).\\nUse Case: When you have many correlated features and want a robust model.\\n'"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Lasso Regression (L1 Regularization):\n",
    "Penalty: Adds the absolute values of the coefficients.\n",
    "Effect: Can shrink some coefficients to zero, effectively performing feature selection.\n",
    "Use Case: When you want to identify the most important features.\n",
    "\n",
    "Ridge Regression (L2 Regularization):\n",
    "Penalty: Adds the squared values of the coefficients.\n",
    "Effect: Shrinks coefficients but does not set them to zero. All features are kept in the model.\n",
    "Use Case: When you want to prevent overfitting while keeping all features.\n",
    "\n",
    "Elastic Net Regression:\n",
    "Penalty: Combines L1 and L2 regularization.\n",
    "Effect: Balances the benefits of both Lasso and Ridge. It can select important features (like Lasso) while also handling multicollinearity (like Ridge).\n",
    "Use Case: When you have many correlated features and want a robust model.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27079446-cbe5-4ff5-9fe0-3b6552b86a4a",
   "metadata": {},
   "source": [
    "Q7. When should we use Elastic Net instead of Lasso or Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "dd0b95c9-390e-45c1-96c2-180d0237d953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nElastic Net is particularly useful when you have a dataset with many features that are highly \\ncorrelated. when you should consider using Elastic Net over Lasso or Ridge:\\n\\nMulticollinearity: If your features are highly correlated, Elastic Net can handle this better than Lasso alone.\\nThe combination of L1 and L2 penalties helps balance between selecting important features and managing multicollinearity.\\n\\nFeature Selection and Regularization: Elastic Net combines the benefits of both Lasso (which performs feature selection by shrinking \\nsome coefficients to zero) and Ridge (which shrinks coefficients without setting them to zero). This balance can lead to better performance.\\n\\nModel Flexibility: Elastic Net provides more flexibility by allowing you to control the balance between L1 and L2 regularization through\\ntwo parameters (𝜆1 and 𝜆2) This flexibility can help in fine-tuning the model to achieve better accuracy.\\n'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Elastic Net is particularly useful when you have a dataset with many features that are highly \n",
    "correlated. when you should consider using Elastic Net over Lasso or Ridge:\n",
    "\n",
    "Multicollinearity: If your features are highly correlated, Elastic Net can handle this better than Lasso alone.\n",
    "The combination of L1 and L2 penalties helps balance between selecting important features and managing multicollinearity.\n",
    "\n",
    "Feature Selection and Regularization: Elastic Net combines the benefits of both Lasso (which performs feature selection by shrinking \n",
    "some coefficients to zero) and Ridge (which shrinks coefficients without setting them to zero). This balance can lead to better performance.\n",
    "\n",
    "Model Flexibility: Elastic Net provides more flexibility by allowing you to control the balance between L1 and L2 regularization through\n",
    "two parameters (𝜆1 and 𝜆2) This flexibility can help in fine-tuning the model to achieve better accuracy.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3ea24a-2f3d-4f26-92ce-d549f146b3d5",
   "metadata": {},
   "source": [
    "Q8.  What is the impact of the regularization parameter (λ) in Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c6b879cc-b938-4058-978c-e6b453935bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe regularization parameter (λ) in Logistic Regression controls the strength of the penalty applied to the model coefficients\\n\\nLow λ: More complex model, higher risk of overfitting.\\n\\nHigh λ: Simpler model, reduced risk of overfitting, but may lead to underfitting if too large.\\n\\nRegularization helps balance the trade-off between bias and variance, leading to better generalization on new data.\\n'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The regularization parameter (λ) in Logistic Regression controls the strength of the penalty applied to the model coefficients\n",
    "\n",
    "Low λ: More complex model, higher risk of overfitting.\n",
    "\n",
    "High λ: Simpler model, reduced risk of overfitting, but may lead to underfitting if too large.\n",
    "\n",
    "Regularization helps balance the trade-off between bias and variance, leading to better generalization on new data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6a3fbc-ce7a-408b-9cd7-179bd9bcc847",
   "metadata": {},
   "source": [
    "Q9.What are the key assumptions of Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "60836fce-1ce4-4645-b23e-bb7239ab0fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nLinearity of Independent Variables and Log Odds: Logistic Regression assumes a linear relationship between \\nthe independent variables and the log odds of the dependent variable.\\n\\nIndependence of Errors: The observations should be independent of each other. In other words,\\nthe error terms should not be correlated.\\n\\nNo Multicollinearity: The independent variables should not be highly correlated with each other.\\nMulticollinearity can lead to unreliable estimates of coefficients.\\n\\nLarge Sample Size: Logistic Regression requires a large sample size to provide reliable estimates.\\nIt works best with a sufficient amount of data.\\n\\nBinary Outcome: The dependent variable should be binary (e.g., 0 or 1, Yes or No).\\n\\nAbsence of Outliers: Outliers can have a significant impact on the model's performance.\\nIt's important to handle or remove outliers before fitting the model.\\n\""
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Linearity of Independent Variables and Log Odds: Logistic Regression assumes a linear relationship between \n",
    "the independent variables and the log odds of the dependent variable.\n",
    "\n",
    "Independence of Errors: The observations should be independent of each other. In other words,\n",
    "the error terms should not be correlated.\n",
    "\n",
    "No Multicollinearity: The independent variables should not be highly correlated with each other.\n",
    "Multicollinearity can lead to unreliable estimates of coefficients.\n",
    "\n",
    "Large Sample Size: Logistic Regression requires a large sample size to provide reliable estimates.\n",
    "It works best with a sufficient amount of data.\n",
    "\n",
    "Binary Outcome: The dependent variable should be binary (e.g., 0 or 1, Yes or No).\n",
    "\n",
    "Absence of Outliers: Outliers can have a significant impact on the model's performance.\n",
    "It's important to handle or remove outliers before fitting the model.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ccf9c8-d6d6-4654-8527-117a97dad305",
   "metadata": {},
   "source": [
    "Q10. What are some alternatives to Logistic Regression for classification tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "758f2fde-3dcf-408f-8f6e-4a26845ee636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Decision Trees: Simple to understand and interpret. They partition data into subsets based on feature values, making decisions based on learned rules.\\n\\nRandom Forests: An ensemble of decision trees that improves accuracy and reduces overfitting by averaging multiple trees.\\n\\nSupport Vector Machines (SVM): Finds the optimal hyperplane that maximizes the margin between different classes. Good for high-dimensional spaces.\\n\\nK-Nearest Neighbors (KNN): Classifies a data point based on the majority class among its k-nearest neighbors.\\n\\nNaive Bayes: Based on Bayes' theorem, this classifier assumes independence between features and works well with small datasets.\\n\\nGradient Boosting Machines (GBM): An ensemble method that builds trees sequentially, each trying to correct the errors of the previous one. Examples include XGBoost and LightGBM.\""
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Decision Trees: Simple to understand and interpret. They partition data into subsets based on feature values, making decisions based on learned rules.\n",
    "\n",
    "Random Forests: An ensemble of decision trees that improves accuracy and reduces overfitting by averaging multiple trees.\n",
    "\n",
    "Support Vector Machines (SVM): Finds the optimal hyperplane that maximizes the margin between different classes. Good for high-dimensional spaces.\n",
    "\n",
    "K-Nearest Neighbors (KNN): Classifies a data point based on the majority class among its k-nearest neighbors.\n",
    "\n",
    "Naive Bayes: Based on Bayes' theorem, this classifier assumes independence between features and works well with small datasets.\n",
    "\n",
    "Gradient Boosting Machines (GBM): An ensemble method that builds trees sequentially, each trying to correct the errors of the previous one. Examples include XGBoost and LightGBM.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affca50b-579e-412b-a180-6313f80918c0",
   "metadata": {},
   "source": [
    " Q.11 What are Classification Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "102674bf-a0cc-48b7-a9c9-05e44c8c2be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nClassification evaluation metrics are used to assess the performance\\nof a classification model.\\nThese metrics help in understanding the strengths and weaknesses of a \\nclassification model and guide improvements in model performance.'"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Classification evaluation metrics are used to assess the performance\n",
    "of a classification model.\n",
    "These metrics help in understanding the strengths and weaknesses of a \n",
    "classification model and guide improvements in model performance.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d6cf40-54d7-428f-9fcf-4ea52f5cb3bc",
   "metadata": {},
   "source": [
    "Q.12 How does class imbalance affect Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "8bda2210-eb7b-43ce-a33f-49f8114471ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Class imbalance affects Logistic Regression by making it biased towards the majority class,\\nresulting in lower precision and recall for the minority class. It can also lead to misleading \\naccuracy and a skewed decision boundary.\\n\\nIn short, Logistic Regression might not perform well on imbalanced datasets without applying techniques\\nlike oversampling the minority class, undersampling the majority class, or using class weights.\\n'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Class imbalance affects Logistic Regression by making it biased towards the majority class,\n",
    "resulting in lower precision and recall for the minority class. It can also lead to misleading \n",
    "accuracy and a skewed decision boundary.\n",
    "\n",
    "In short, Logistic Regression might not perform well on imbalanced datasets without applying techniques\n",
    "like oversampling the minority class, undersampling the majority class, or using class weights.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8242d343-e4bf-4386-8d0f-b06c613ad001",
   "metadata": {},
   "source": [
    "Q13.  What is Hyperparameter Tuning in Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "b4ee4e44-5f09-4f76-9188-a4949ec67800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nHyperparameter tuning in Logistic Regression involves adjusting the model's hyperparameters to improve its performance.\\nKey hyperparameters to tune include:\\n\\nRegularization Parameter (C): Controls the trade-off between fitting the training data and keeping\\nthe model simple (smaller C means stronger regularization).\\n\\nRegularization Type (L1 or L2): Determines the type of regularization applied (L1 can lead to sparse \\nmodels, while L2 tends to keep all features).\""
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Hyperparameter tuning in Logistic Regression involves adjusting the model's hyperparameters to improve its performance.\n",
    "Key hyperparameters to tune include:\n",
    "\n",
    "Regularization Parameter (C): Controls the trade-off between fitting the training data and keeping\n",
    "the model simple (smaller C means stronger regularization).\n",
    "\n",
    "Regularization Type (L1 or L2): Determines the type of regularization applied (L1 can lead to sparse \n",
    "models, while L2 tends to keep all features).\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01288933-96c7-4e4d-8451-5e9b3137a465",
   "metadata": {},
   "source": [
    "Q14.  What are different solvers in Logistic Regression? Which one should be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f6d0faa5-2812-4886-945c-630ce333d113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nsome common solvers used in Logistic Regression:\\n\\nliblinear: Good for small datasets; it uses a coordinate descent algorithm.\\nnewton-cg: Suitable for large datasets; uses Newton's method for optimization.\\nlbfgs: Handles large datasets and is efficient for multiclass problems; it's a quasi-Newton method.\\nsag: Stochastic Average Gradient Descent; faster for large datasets.\\nsaga: Similar to SAG but also supports L1 regularization.\\n\\nWhich one to use:\\n\\nFor smaller datasets, liblinear is a good choice.\\nFor larger datasets, lbfgs, newton-cg, or sag are recommended.\\nFor both large datasets and L1 regularization, saga is a good option.\""
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "some common solvers used in Logistic Regression:\n",
    "\n",
    "liblinear: Good for small datasets; it uses a coordinate descent algorithm.\n",
    "newton-cg: Suitable for large datasets; uses Newton's method for optimization.\n",
    "lbfgs: Handles large datasets and is efficient for multiclass problems; it's a quasi-Newton method.\n",
    "sag: Stochastic Average Gradient Descent; faster for large datasets.\n",
    "saga: Similar to SAG but also supports L1 regularization.\n",
    "\n",
    "Which one to use:\n",
    "\n",
    "For smaller datasets, liblinear is a good choice.\n",
    "For larger datasets, lbfgs, newton-cg, or sag are recommended.\n",
    "For both large datasets and L1 regularization, saga is a good option.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0eb099-3c71-4946-8662-813a5a56a3f8",
   "metadata": {},
   "source": [
    "Q15.  How is Logistic Regression extended for multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "de130fba-dd61-4890-9e4c-01541602bebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nLogistic Regression can be extended for multiclass classification using the following approaches:\\n\\nOne-vs-Rest (OvR): The model is trained to separate each class from the rest. \\nIt creates one binary classifier per class.\\n\\nOne-vs-One (OvO): The model is trained on all possible pairs of classes,\\ncreating one binary classifier for each pair.\\n\\nThe most common method is One-vs-Rest (OvR), as it's simpler and scales well with the number of classes.\""
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Logistic Regression can be extended for multiclass classification using the following approaches:\n",
    "\n",
    "One-vs-Rest (OvR): The model is trained to separate each class from the rest. \n",
    "It creates one binary classifier per class.\n",
    "\n",
    "One-vs-One (OvO): The model is trained on all possible pairs of classes,\n",
    "creating one binary classifier for each pair.\n",
    "\n",
    "The most common method is One-vs-Rest (OvR), as it's simpler and scales well with the number of classes.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9743aa-c9b2-47c8-83c9-6561d1bd17ae",
   "metadata": {},
   "source": [
    " Q.16 What are the advantages and disadvantages of Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "01713800-5686-44a1-a581-3441eca1f97f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAdvantages:\\n\\nSimplicity: Easy to implement and interpret.\\n\\nEfficiency: Fast to train and works well with large datasets.\\n\\nProbabilistic Output: Provides probability scores for observations.\\n\\nDisadvantages:\\n\\nLinear Decision Boundary: Assumes a linear relationship between features and the log-odds.\\n\\nNot Suitable for Complex Relationships: Struggles with non-linear data without transformations.\\n\\nSensitive to Imbalanced Data: Performance can be heavily affected by class imbalance.'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Advantages:\n",
    "\n",
    "Simplicity: Easy to implement and interpret.\n",
    "\n",
    "Efficiency: Fast to train and works well with large datasets.\n",
    "\n",
    "Probabilistic Output: Provides probability scores for observations.\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "Linear Decision Boundary: Assumes a linear relationship between features and the log-odds.\n",
    "\n",
    "Not Suitable for Complex Relationships: Struggles with non-linear data without transformations.\n",
    "\n",
    "Sensitive to Imbalanced Data: Performance can be heavily affected by class imbalance.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18efebb2-560d-45b6-95d5-a4e772e8f7d2",
   "metadata": {},
   "source": [
    " Q.17 What are some use cases of Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "abddef56-7091-4d3b-9728-42596f371e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUse Cases of Logistic Regression:\\n\\nBinary Classification: Spam detection, disease diagnosis, etc.\\n\\nCredit Scoring: Assessing the likelihood of a borrower defaulting.\\n\\nMarketing Campaigns: Predicting customer responses to marketing efforts.'"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Use Cases of Logistic Regression:\n",
    "\n",
    "Binary Classification: Spam detection, disease diagnosis, etc.\n",
    "\n",
    "Credit Scoring: Assessing the likelihood of a borrower defaulting.\n",
    "\n",
    "Marketing Campaigns: Predicting customer responses to marketing efforts.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a4bb46-ade9-49be-9c4b-43843a452d28",
   "metadata": {},
   "source": [
    " Q.18 What is the difference between Softmax Regression and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "2768a70d-bb5f-4a7e-97e9-fe32520a1f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDifference Between Softmax Regression and Logistic Regression\\nLogistic Regression: Used for binary classification. It outputs probabilities for two classes.\\n\\nSoftmax Regression: Used for multiclass classification. It outputs probabilities for multiple classes,\\nensuring the sum of probabilities for all classes equals 1.'"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Difference Between Softmax Regression and Logistic Regression\n",
    "Logistic Regression: Used for binary classification. It outputs probabilities for two classes.\n",
    "\n",
    "Softmax Regression: Used for multiclass classification. It outputs probabilities for multiple classes,\n",
    "ensuring the sum of probabilities for all classes equals 1.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9c2eba-b776-4afd-9d5c-e07e89053667",
   "metadata": {},
   "source": [
    " Q.19 How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "64d14998-652a-40ab-a230-03026f110e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nChoosing Between One-vs-Rest (OvR) and Softmax for Multiclass Classification:\\n\\nOne-vs-Rest (OvR): Simpler and works well for most multiclass problems.\\n\\nSoftmax: Preferred when the model is needed to consider the relationship between multiple \\nclasses simultaneously.'"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Choosing Between One-vs-Rest (OvR) and Softmax for Multiclass Classification:\n",
    "\n",
    "One-vs-Rest (OvR): Simpler and works well for most multiclass problems.\n",
    "\n",
    "Softmax: Preferred when the model is needed to consider the relationship between multiple \n",
    "classes simultaneously.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528dfd60-88a6-413b-b6a4-1b3771bab992",
   "metadata": {},
   "source": [
    " Q.20 How do we interpret coefficients in Logistic Regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "edda0521-01fa-4bfa-941e-e7dc7185f84b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nInterpreting Coefficients in Logistic Regression:\\n\\nCoefficients (β): Represent the change in the log-odds of the outcome for a one-unit increase in the predictor variable.\\n\\nExponential of Coefficients: \\n𝑒^𝛽 represents the odds ratio, which indicates how much the odds of the outcome increase (if >1) or decrease (if <1) with a one-unit increase in the predictor.'"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Interpreting Coefficients in Logistic Regression:\n",
    "\n",
    "Coefficients (β): Represent the change in the log-odds of the outcome for a one-unit increase in the predictor variable.\n",
    "\n",
    "Exponential of Coefficients: \n",
    "𝑒^𝛽 represents the odds ratio, which indicates how much the odds of the outcome increase (if >1) or decrease (if <1) with a one-unit increase in the predictor.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8afe16-2666-4b0f-8355-260803503a53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91778c93-668b-464d-8ec2-7d436a184d47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36a69989-48cf-419e-8db1-9ba3e0de8816",
   "metadata": {},
   "source": [
    "## Practical Question "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca97eb47-69bd-4bb8-b537-c8291ff3e392",
   "metadata": {},
   "source": [
    " Q1. Write a Python program that loads a dataset, splits it into training and testing sets, applies Logistic \n",
    "Regression, and prints the model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "d1d90748-882c-451a-a81c-6c2aa5841817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=200)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Logistic Regression Model Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da66d0f0-1677-43da-bc9c-79d27677445f",
   "metadata": {},
   "source": [
    " Q2. Write a Python program to apply L1 regularization (Lasso) on a dataset using LogisticRegression(penalty='l1') \n",
    "and print the model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "6454da7d-9f58-4445-bfc6-cd651c0202f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 Regularized (Lasso) Logistic Regression Model Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "log_reg_l1 = LogisticRegression(penalty='l1', solver='liblinear', max_iter=200)\n",
    "log_reg_l1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = log_reg_l1.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'L1 Regularized (Lasso) Logistic Regression Model Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c42ad8-010d-4615-8039-851dc08aac33",
   "metadata": {},
   "source": [
    "Q3. Write a Python program to train Logistic Regression with L2 regularization (Ridge) using \n",
    "LogisticRegression(penalty='l2'). Print model accuracy and coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "154e61a8-8aea-47a8-bf3e-996709273819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 Regularized (Ridge) Logistic Regression Model Accuracy: 1.0\n",
      "Model Coefficients: [[ 0.3711229   1.409712   -2.15210117 -0.95474179]\n",
      " [ 0.49400451 -1.58897112  0.43717015 -1.11187838]\n",
      " [-1.55895271 -1.58893375  2.39874554  2.15556209]]\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "log_reg_l2 = LogisticRegression(penalty='l2', solver='liblinear', max_iter=200)\n",
    "log_reg_l2.fit(X_train, y_train)\n",
    "\n",
    "y_pred = log_reg_l2.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "coefficients = log_reg_l2.coef_\n",
    "print(f'L2 Regularized (Ridge) Logistic Regression Model Accuracy: {accuracy}')\n",
    "print(f'Model Coefficients: {coefficients}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe29647-5aeb-485d-9d33-00260d921ebb",
   "metadata": {},
   "source": [
    "Q4. Write a Python program to train Logistic Regression with Elastic Net Regularization (penalty='elasticnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "80445e13-b67b-4a59-b1ee-630a347ed1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elastic Net Regularized Logistic Regression Model Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "log_reg_en = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, max_iter=200)\n",
    "log_reg_en.fit(X_train, y_train)\n",
    "y_pred_en = log_reg_en.predict(X_test)\n",
    "accuracy_en = accuracy_score(y_test, y_pred_en)\n",
    "print(f'Elastic Net Regularized Logistic Regression Model Accuracy: {accuracy_en}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea64218-89b5-4cdc-bf08-48daeb9549ba",
   "metadata": {},
   "source": [
    "Q5. Write a Python program to train a Logistic Regression model for multiclass classification using \n",
    "multi_class='ovr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "7fe9801b-592e-4ab6-9d52-651b1347158e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass (OvR) Logistic Regression Model Accuracy: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "\n",
    "log_reg_ovr = LogisticRegression(multi_class='ovr', max_iter=200)\n",
    "log_reg_ovr.fit(X_train, y_train)\n",
    "y_pred_ovr = log_reg_ovr.predict(X_test)\n",
    "accuracy_ovr = accuracy_score(y_test, y_pred_ovr)\n",
    "print(f'Multiclass (OvR) Logistic Regression Model Accuracy: {accuracy_ovr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f33cf8-12d4-4e50-b494-c518bdc45014",
   "metadata": {},
   "source": [
    " Q6. Write a Python program to apply GridSearchCV to tune the hyperparameters (C and penalty) of Logistic Regression. Print the best parameters and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "be780a48-9c0a-424c-a3fd-dd0d481c0c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "GridSearchCV Logistic Regression Model Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "param_grid = {'C': [0.1, 1, 10], 'penalty': ['l1', 'l2'], 'solver': ['liblinear']}\n",
    "grid_search = GridSearchCV(LogisticRegression(max_iter=200), param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "best_estimator = grid_search.best_estimator_\n",
    "y_pred_gs = best_estimator.predict(X_test)\n",
    "accuracy_gs = accuracy_score(y_test, y_pred_gs)\n",
    "print(f'Best Parameters: {best_params}')\n",
    "print(f'GridSearchCV Logistic Regression Model Accuracy: {accuracy_gs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777bfd74-5a86-4c3b-8619-4f5a5bc390dd",
   "metadata": {},
   "source": [
    " Q7. Write a Python program to evaluate Logistic Regression using Stratified K-Fold Cross-Validation. Print the \n",
    "average accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "1a2c8834-10c6-4280-aaa2-8d2892cac5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified K-Fold Cross-Validation Average Accuracy: 0.9666666666666666\n"
     ]
    }
   ],
   "source": [
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "log_reg_cv = LogisticRegression(max_iter=200)\n",
    "cv_scores = cross_val_score(log_reg_cv, X_train, y_train, cv=skf)\n",
    "average_accuracy = cv_scores.mean()\n",
    "print(f'Stratified K-Fold Cross-Validation Average Accuracy: {average_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c85b706-9325-4cb0-a43d-3d0bf2863f1f",
   "metadata": {},
   "source": [
    " Q8. Write a Python program to load a dataset from a CSV file, apply Logistic Regression, and evaluate its \n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "5a3aa3a7-4dd5-4d5b-9712-abfba0dfdc2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV Dataset Logistic Regression Model Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "df.to_csv('iris_dataset.csv', index=False)\n",
    "\n",
    "df = pd.read_csv('iris_dataset.csv')\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "df = pd.read_csv('iris_dataset.csv')\n",
    "X_csv = df.drop('target', axis=1)\n",
    "y_csv = df['target']\n",
    "X_train_csv, X_test_csv, y_train_csv, y_test_csv = train_test_split(X_csv, y_csv, test_size=0.2, random_state=42)\n",
    "log_reg_csv = LogisticRegression(max_iter=1000)\n",
    "log_reg_csv.fit(X_train_csv, y_train_csv)\n",
    "y_pred_csv = log_reg_csv.predict(X_test_csv)\n",
    "accuracy_csv = accuracy_score(y_test_csv, y_pred_csv)\n",
    "print(f'CSV Dataset Logistic Regression Model Accuracy: {accuracy_csv}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705472df-f30d-4c65-be6c-93593e4d18e1",
   "metadata": {},
   "source": [
    "Q9. Write a Python program to apply RandomizedSearchCV for tuning hyperparameters (C, penalty, solver) in \n",
    "Logistic Regression. Print the best parameters and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "dc0c1ab7-667b-4dcf-9dd3-2245aed8307a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'solver': 'saga', 'penalty': 'l2', 'C': 10}\n",
      "RandomizedSearchCV Logistic Regression Model Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "\n",
    "param_grid = {'C': [0.1, 1, 10], 'penalty': ['l1', 'l2', 'elasticnet'], 'solver': ['liblinear', 'saga']}\n",
    "random_search = RandomizedSearchCV(LogisticRegression(max_iter=1000), param_grid, n_iter=10, cv=5, random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "best_params = random_search.best_params_\n",
    "best_estimator = random_search.best_estimator_\n",
    "y_pred_rs = best_estimator.predict(X_test)\n",
    "accuracy_rs = accuracy_score(y_test, y_pred_rs)\n",
    "print(f'Best Parameters: {best_params}')\n",
    "print(f'RandomizedSearchCV Logistic Regression Model Accuracy: {accuracy_rs}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a924995b-94fc-4b04-9630-03c5bb612491",
   "metadata": {},
   "source": [
    "Q10. Write a Python program to implement One-vs-One (OvO) Multiclass Logistic Regression and print accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "ed62ecb3-7458-422c-9550-afe53ebd23bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass (OvR) Logistic Regression Model Accuracy: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "\n",
    "log_reg_ovr = LogisticRegression(multi_class='ovr', max_iter=1000)\n",
    "log_reg_ovr.fit(X_train, y_train)\n",
    "y_pred_ovr = log_reg_ovr.predict(X_test)\n",
    "accuracy_ovr = accuracy_score(y_test, y_pred_ovr)\n",
    "print(f'Multiclass (OvR) Logistic Regression Model Accuracy: {accuracy_ovr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791b420a-3b0e-4cea-affe-dcd765983df6",
   "metadata": {},
   "source": [
    "Q11. Write a Python program to train a Logistic Regression model and visualize the confusion matrix for binary \n",
    "classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "b281fe57-a4f8-4393-b8c6-5890d3f602ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'solver': 'saga', 'penalty': 'l2', 'C': 10}\n",
      "RandomizedSearchCV Logistic Regression Model Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "param_grid = {'C': [0.1, 1, 10], 'penalty': ['l1', 'l2', 'elasticnet'], 'solver': ['liblinear', 'saga']}\n",
    "random_search = RandomizedSearchCV(LogisticRegression(max_iter=1000), param_grid, n_iter=10, cv=5, random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "best_params = random_search.best_params_\n",
    "best_estimator = random_search.best_estimator_\n",
    "y_pred_rs = best_estimator.predict(X_test)\n",
    "accuracy_rs = accuracy_score(y_test, y_pred_rs)\n",
    "print(f'Best Parameters: {best_params}')\n",
    "print(f'RandomizedSearchCV Logistic Regression Model Accuracy: {accuracy_rs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714cd8eb-05f9-4615-ad81-ea4734d7f699",
   "metadata": {},
   "source": [
    "Q12. Write a Python program to train a Logistic Regression model and evaluate its performance using Precision, \n",
    "Recall, and F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "9c081813-a783-4b60-9ec1-60612beced6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.91\n",
      "Recall: 0.80\n",
      "F1-Score: 0.86\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1-Score: {f1:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def096cb-dea5-4125-8bc3-854a0282c321",
   "metadata": {},
   "source": [
    "Q13. Write a Python program to train a Logistic Regression model on imbalanced data and apply class weights to \n",
    "improve model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "009d08a4-ca07-4180-9618-a1496c183002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imbalanced Data Logistic Regression Model Accuracy: 0.815\n"
     ]
    }
   ],
   "source": [
    "imbalanced_X_train, imbalanced_y_train = resample(X_train, y_train, n_samples=200, random_state=42, stratify=y_train)\n",
    "log_reg_imbalanced = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
    "log_reg_imbalanced.fit(imbalanced_X_train, imbalanced_y_train)\n",
    "y_pred_imbalanced = log_reg_imbalanced.predict(X_test)\n",
    "accuracy_imbalanced = accuracy_score(y_test, y_pred_imbalanced)\n",
    "print(f'Imbalanced Data Logistic Regression Model Accuracy: {accuracy_imbalanced}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d387e38d-41d9-49d0-b429-7397928bbd92",
   "metadata": {},
   "source": [
    "Q14. Write a Python program to train Logistic Regression on the Titanic dataset, handle missing values, and \n",
    "evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "68487fdf-7bb8-44b8-9692-a51dc0b9d12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model Accuracy: 0.8044692737430168\n",
      "Precision: 0.7746478873239436\n",
      "Recall: 0.7432432432432432\n",
      "F1-Score: 0.7586206896551724\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/chaitanya-0b10/Assignment-Logistic-Regreession-/refs/heads/main/train.csv')\n",
    "\n",
    "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
    "df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
    "df['Fare'].fillna(df['Fare'].median(), inplace=True)\n",
    "\n",
    "df = pd.get_dummies(df, columns=['Sex', 'Embarked'], drop_first=True)\n",
    "\n",
    "df.drop(['Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
    "\n",
    "X = df.drop('Survived', axis=1)\n",
    "y = df['Survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = log_reg.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f'Logistic Regression Model Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1-Score: {f1}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b308945-946d-4b93-b725-a945f32d9f6c",
   "metadata": {},
   "source": [
    "Q15. Write a Python program to apply feature scaling (Standardization) before training a Logistic Regression \n",
    "model. Evaluate its accuracy and compare results with and without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "a3e062ca-a3b4-4258-8e3f-ed46f189cece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled Logistic Regression Model Accuracy: 0.8044692737430168\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "log_reg_scaled = LogisticRegression(max_iter=1000)\n",
    "log_reg_scaled.fit(X_train_scaled, y_train)\n",
    "y_pred_scaled = log_reg_scaled.predict(X_test_scaled)\n",
    "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
    "print(f'Scaled Logistic Regression Model Accuracy: {accuracy_scaled}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1befe5-1bfc-4d1a-b1a3-dd33282c5923",
   "metadata": {},
   "source": [
    "Q16.  Write a Python program to train Logistic Regression and evaluate its performance using ROC-AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "97f2114d-5538-4f54-aebe-a655f22d41d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC Score: 0.9976484420928865\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_probs = model.predict_proba(X_test)[:, 1]\n",
    "roc_auc = roc_auc_score(y_test, y_probs)\n",
    "print(f\"ROC-AUC Score: {roc_auc}\")\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
    "plt.plot(fpr, tpr, color='b', label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afde4101-afb3-444b-981f-e0c5fb02c329",
   "metadata": {},
   "source": [
    "Q17. Write a Python program to train Logistic Regression using a custom learning rate (C=0.5) and evaluate \n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "e1c58277-3ba2-47c7-8853-2e472848e918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9766081871345029\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "model = LogisticRegression(C=0.5, max_iter=10000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f396b2f6-b825-4f8a-876e-3426992a0e36",
   "metadata": {},
   "source": [
    "Q18. Write a Python program to train Logistic Regression and identify important features based on model \n",
    "coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "0eaf267d-a9ad-425e-a063-37f17d9088f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Important features based on model coefficients:\n",
      "worst concavity: -1.4401587744520012\n",
      "texture error: 1.2354096544808437\n",
      "mean radius: 1.0016328790485955\n",
      "worst symmetry: -0.7347089381329279\n",
      "worst compactness: -0.6723172871076203\n",
      "worst concave points: -0.620546595942859\n",
      "mean concavity: -0.5430435393003425\n",
      "worst texture: -0.43602294502776917\n",
      "worst smoothness: -0.36897025011676704\n",
      "mean concave points: -0.30391708785385485\n",
      "mean perimeter: -0.27887770133408535\n",
      "mean symmetry: -0.2718454470027267\n",
      "mean compactness: -0.21625051884391752\n",
      "mean smoothness: -0.18377337094550358\n",
      "mean texture: 0.17919991508243013\n",
      "perimeter error: 0.14520862501386642\n",
      "worst radius: 0.14021728725344523\n",
      "area error: -0.11043214754034263\n",
      "worst perimeter: -0.10879383752819702\n",
      "worst fractal dimension: -0.09307493890395087\n",
      "radius error: -0.07862890552056011\n",
      "compactness error: 0.07556912613278263\n",
      "concave points error: -0.03931856547011623\n",
      "symmetry error: -0.03499984233077999\n",
      "concavity error: -0.03192580401054099\n",
      "mean fractal dimension: -0.02979774069872282\n",
      "smoothness error: -0.02662702370615321\n",
      "mean area: 0.02310955086813297\n",
      "fractal dimension error: 0.015318793008917192\n",
      "worst area: -0.013552389979891033\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "model.fit(X, y)\n",
    "coefficients = model.coef_[0]\n",
    "feature_names = data.feature_names\n",
    "\n",
    "\n",
    "feature_importance = np.abs(coefficients)\n",
    "sorted_idx = np.argsort(feature_importance)[::-1]\n",
    "\n",
    "print(\"Important features based on model coefficients:\")\n",
    "for idx in sorted_idx:\n",
    "    print(f\"{feature_names[idx]}: {coefficients[idx]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cc4519-b1d0-4caf-86ee-48936c3d131e",
   "metadata": {},
   "source": [
    "Q19. Write a Python program to train Logistic Regression and evaluate its performance using Cohen’s Kappa \n",
    "Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "59577625-cb0a-443b-b441-b1db09eb7074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's Kappa Score: 0.9497354497354498\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "kappa_score = cohen_kappa_score(y_test, y_pred)\n",
    "print(f\"Cohen's Kappa Score: {kappa_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb86f0d1-eb84-4d42-beb5-cb10c0916a71",
   "metadata": {},
   "source": [
    "Q20. Write a Python program to train Logistic Regression and visualize the Precision-Recall Curve for binary \n",
    "classificatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "952fd752-14b7-4d35-8e50-471359d5c0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_probs = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_probs)\n",
    "\n",
    "\n",
    "plt.plot(recall, precision, color='b')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b608727-8ddc-4cb4-b3ed-ac4f356c2769",
   "metadata": {},
   "source": [
    "Q21. Write a Python program to train Logistic Regression with different solvers (liblinear, saga, lbfgs) and compare \n",
    "their accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "c030055d-5f3e-4d46-a6d0-e21326684b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with solver liblinear: 0.9649122807017544\n",
      "Accuracy with solver saga: 0.9649122807017544\n",
      "Accuracy with solver lbfgs: 0.9766081871345029\n",
      "\n",
      "Comparison of Solvers:\n",
      "liblinear: 0.9649122807017544\n",
      "saga: 0.9649122807017544\n",
      "lbfgs: 0.9766081871345029\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "solvers = ['liblinear', 'saga', 'lbfgs']\n",
    "accuracy_results = {}\n",
    "\n",
    "for solver in solvers:\n",
    "    model = LogisticRegression(solver=solver, max_iter=10000)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_results[solver] = accuracy\n",
    "    print(f\"Accuracy with solver {solver}: {accuracy}\")\n",
    "\n",
    "print(\"\\nComparison of Solvers:\")\n",
    "for solver, accuracy in accuracy_results.items():\n",
    "    print(f\"{solver}: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d8abd0-1820-44fe-bcdc-ebf628f5c0d2",
   "metadata": {},
   "source": [
    "Q22. Write a Python program to train Logistic Regression and evaluate its performance using Matthews \n",
    "Correlation Coefficient (MCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "f6e8ec3d-87ea-433b-87f3-4f5a99e537bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthews Correlation Coefficient (MCC): 0.9497354497354498\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "# Load dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train Logistic Regression\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Matthews Correlation Coefficient (MCC)\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "print(f\"Matthews Correlation Coefficient (MCC): {mcc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ac5ab2-8995-4963-908c-63e4b1db27a4",
   "metadata": {},
   "source": [
    "Q23. Write a Python program to train Logistic Regression on both raw and standardized data. Compare their \n",
    "accuracy to see the impact of feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "10d52632-3fe1-48af-94bc-8abee4af481b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with raw data: 0.9766081871345029\n",
      "Accuracy with standardized data: 0.9824561403508771\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train Logistic Regression on raw data\n",
    "model_raw = LogisticRegression(max_iter=10000)\n",
    "model_raw.fit(X_train, y_train)\n",
    "y_pred_raw = model_raw.predict(X_test)\n",
    "accuracy_raw = accuracy_score(y_test, y_pred_raw)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train Logistic Regression on standardized data\n",
    "model_scaled = LogisticRegression(max_iter=10000)\n",
    "model_scaled.fit(X_train_scaled, y_train)\n",
    "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
    "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
    "\n",
    "# Compare accuracy\n",
    "print(f\"Accuracy with raw data: {accuracy_raw}\")\n",
    "print(f\"Accuracy with standardized data: {accuracy_scaled}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8609fca5-8fa5-431a-8ed5-f0b2c34c6876",
   "metadata": {},
   "source": [
    "Q24. Write a Python program to train Logistic Regression and find the optimal C (regularization strength) using \n",
    "cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "e6a69808-6fbf-4b73-9364-210bea3a5f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal C: 100\n",
      "Best cross-validation accuracy: 0.9647784810126583\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Load dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Set up parameter grid for cross-validation\n",
    "param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_C = grid_search.best_params_['C']\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f\"Optimal C: {best_C}\")\n",
    "print(f\"Best cross-validation accuracy: {best_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d34481-ce95-4b35-8595-be26663fc31f",
   "metadata": {},
   "source": [
    "Q25. write a Python program to train Logistic Regression, save the trained model using joblib, and load it again to \n",
    "make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "cc6ce245-32e9-440a-97ff-08801e963a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the loaded model: 0.9766081871345029\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "joblib.dump(model, 'logistic_regression_model.pkl')\n",
    "\n",
    "loaded_model = joblib.load('logistic_regression_model.pkl')\n",
    "\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy of the loaded model: {accuracy}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
